{
  "id": "f6eb7132-5484-4625-8ba0-c92251ebe0df",
  "revision": 0,
  "last_node_id": 13,
  "last_link_id": 10,
  "nodes": [
    {
      "id": 1,
      "type": "LoaderGGUF",
      "pos": [
        224.73321533203125,
        1095.1239013671875
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            1
          ]
        }
      ],
      "properties": {
        "cnr_id": "gguf",
        "ver": "2.5.5",
        "Node name for S&R": "LoaderGGUF"
      },
      "widgets_values": [
        "hunyuanimage2.1-q4_k_s.gguf"
      ]
    },
    {
      "id": 4,
      "type": "ModelSamplingSD3",
      "pos": [
        657.80810546875,
        1094.7088623046875
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 1
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            2
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "ModelSamplingSD3"
      },
      "widgets_values": [
        5
      ]
    },
    {
      "id": 2,
      "type": "DualClipLoaderGGUF",
      "pos": [
        226.0631103515625,
        1207.3790283203125
      ],
      "size": [
        270,
        130
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            3,
            4
          ]
        }
      ],
      "properties": {
        "cnr_id": "gguf",
        "ver": "2.5.5",
        "Node name for S&R": "DualClipLoaderGGUF"
      },
      "widgets_values": [
        "Qwen2.5-VL-7B-Instruct-Q4_K_M.gguf",
        "byt5_small_glyphxl_fp32-f16.gguf",
        "hunyuan_image",
        "default"
      ]
    },
    {
      "id": 8,
      "type": "EmptyHunyuanImageLatent",
      "pos": [
        1194.647705078125,
        1448.8154296875
      ],
      "size": [
        273.3999938964844,
        106
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            7
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "EmptyHunyuanImageLatent"
      },
      "widgets_values": [
        2048,
        2048,
        1
      ]
    },
    {
      "id": 5,
      "type": "KSampler",
      "pos": [
        1196.541259765625,
        1103.2315673828125
      ],
      "size": [
        270,
        262
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 2
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 5
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 7
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            8
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        707680996522865,
        "randomize",
        20,
        3.5,
        "euler",
        "beta",
        1
      ]
    },
    {
      "id": 3,
      "type": "VaeGGUF",
      "pos": [
        229.85043334960938,
        1383.4844970703125
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            9
          ]
        }
      ],
      "properties": {
        "cnr_id": "gguf",
        "ver": "2.5.5",
        "Node name for S&R": "VaeGGUF"
      },
      "widgets_values": [
        "pig_hunyuan_image_vae_fp32-f16.gguf"
      ]
    },
    {
      "id": 9,
      "type": "VAEDecode",
      "pos": [
        1537.392822265625,
        1107.9652099609375
      ],
      "size": [
        140,
        46
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 8
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 9
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            10
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 10,
      "type": "SaveImage",
      "pos": [
        1709.190185546875,
        1107.5377197265625
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 10
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        598.1591796875,
        1210.2205810546875
      ],
      "size": [
        400,
        200
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 3
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            5
          ]
        }
      ],
      "title": "Positive Prompt",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "Hyper-realistic portrait of a young woman with freckles and curly hair, soft sunlight falling on her face, realistic skin texture, natural makeup, subtle depth of field, cinematic lighting, 8K resolution, professional photography style."
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        598.4254150390625,
        1450.9759521484375
      ],
      "size": [
        400,
        200
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 4
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            6
          ]
        }
      ],
      "title": "Negative Prompt",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "low quality, bad anatomy, extra digits, missing digits, extra limbs, missing limbs\n"
      ]
    },
    {
      "id": 11,
      "type": "Note",
      "pos": [
        1200.4229736328125,
        1598.5997314453125
      ],
      "size": [
        439.94873046875,
        287.0445251464844
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "Other Best Resolutions\n\n 16:9  -> width=2560, height=1536\n\n 4:3   -> width=2304, height=1792\n\n 1:1   -> width=2048, height=2048\n\n 3:4   -> width=1792, height=2304\n\n 9:16  -> width=1536, height=2560"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 13,
      "type": "MarkdownNote",
      "pos": [
        -101.43778228759766,
        1066.3990478515625
      ],
      "size": [
        299.3477478027344,
        393.2763671875
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "GGUF Model Links",
      "properties": {},
      "widgets_values": [
        "**Diffusion Model**\n\n[Hunyuanimage2.1 GGUF](https://huggingface.co/calcuis/hunyuanimage-gguf/tree/main)\n\n**Text Encoders**\n\n[ByT5 small glyphxl](https://huggingface.co/calcuis/pig-encoder/tree/main)\n\n[Qwen2.5 VL 7B Instruct GGUF](https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF/tree/main\n)\n\n**VAE**\n\n[VAE](https://huggingface.co/calcuis/pig-vae/blob/main/pig_hunyuan_image_vae_fp32-f16.gguf\n)\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    }
  ],
  "links": [
    [
      1,
      1,
      0,
      4,
      0,
      "MODEL"
    ],
    [
      2,
      4,
      0,
      5,
      0,
      "MODEL"
    ],
    [
      3,
      2,
      0,
      6,
      0,
      "CLIP"
    ],
    [
      4,
      2,
      0,
      7,
      0,
      "CLIP"
    ],
    [
      5,
      6,
      0,
      5,
      1,
      "CONDITIONING"
    ],
    [
      6,
      7,
      0,
      5,
      2,
      "CONDITIONING"
    ],
    [
      7,
      8,
      0,
      5,
      3,
      "LATENT"
    ],
    [
      8,
      5,
      0,
      9,
      0,
      "LATENT"
    ],
    [
      9,
      3,
      0,
      9,
      1,
      "VAE"
    ],
    [
      10,
      9,
      0,
      10,
      0,
      "IMAGE"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.9601641144725224,
      "offset": [
        55.61228615341534,
        -1135.1372754944505
      ]
    },
    "frontendVersion": "1.25.11"
  },
  "version": 0.4
}